{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning DETR on TACO (and another detect-waste datasets)\n",
    "\n",
    "Credits:\n",
    "- [Sylwia Majchrowska](https://github.com/majsylw)\n",
    "\n",
    "Adapted from:\n",
    "-   https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_attention.ipynb\n",
    "-   https://github.com/woctezuma/finetune-detr\n",
    "\n",
    "Parameters:\n",
    "- Official DETR repository: https://github.com/facebookresearch/detr\n",
    "- Optimizer: AdamW or LaProp\n",
    "- Number of class:\n",
    "  - 6 (paper, metals and plastics, bio, other, non-recycle, glass) [for 1.5k TACO only],\n",
    "  - 7 (paper, metals and plastics, bio, other, non-recycle, glass, unknown),\n",
    "  - or 1 (litter).\n",
    "- Backbone: ResNet50, ResNet101\n",
    "- Num queries: 100 (like in official Detr it coressponds to max number of instances per images - this should not be changed if we finetuned)\n",
    "- Eos coef: 0.1 (like in official Detr mean number of instances per image - this should not be changed if we finetuned)\n",
    "- 300 epochs at lr 1e-4 with lr_drop to 1e-5 at 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "1. [Taco](http://tacodataset.org/)\n",
    "  - Relatively small with ~1k Train, 150 validation images\n",
    "  - We additionaly add ~3.5k images with bbox annotations\n",
    "  - To contrast The COCO dataset is an excellent object detection dataset with 80 classes, 80,000 training images and 40,000 validation images\n",
    "2. Multi - mixed few object detection/segmentation waste datasets mentioned in main ```README.md```\n",
    "  - 19798 training, 4940 validation images from about 7 waste dataset from different enviroments (1 class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare coco annotations:\n",
    "- 1 class - litter,\n",
    "- 6 classes - paper, metals and plastics, bio, other, non-recycle, glass\n",
    "- 7 classes - paper, metals and plastics, bio, other, non-recycle, glass, unknown.\n",
    "\n",
    "Can be found at `annotations` directory (check its ```README``` file).\n",
    "\n",
    "### 1.2 Download all images\n",
    "- all links to waste datasets used in this projet are provieded in main ```README.md```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from shutil import copyfile\n",
    "import os\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annFile='../../annotations/annotations_test.json' # path to example annotations\n",
    "dataDir = '/dih4/dih4_2/wimlds/data/all_detect_images' # path to your directory with images - TO CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize COCO api for instance annotations\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display COCO categories and supercategories\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms=[cat['name'] for cat in cats]\n",
    "print('COCO categories: \\n{}\\n'.format(', '.join(nms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display image\n",
    "catIds = coco.getCatIds(catNms=['non recyclable'])\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "img_id = imgIds[np.random.randint(0,len(imgIds))]\n",
    "print('Image nÂ°{}'.format(img_id))\n",
    "\n",
    "img = coco.loadImgs(img_id)[0]\n",
    "\n",
    "img_name = '%s/%s'%(dataDir, img['file_name'])\n",
    "print('Image name: {}'.format(img_name))\n",
    "\n",
    "I = io.imread(img_name)\n",
    "plt.figure()\n",
    "plt.imshow(I)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display instance annotations\n",
    "plt.imshow(I); plt.axis('off')\n",
    "annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds)\n",
    "anns = coco.loadAnns(annIds)\n",
    "coco.showAnns(anns, draw_bbox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Please just follow notes described in readme file tu run script ``main.py`` with parameters from command line.\n",
    "\n",
    "For example:\n",
    "```python3 main.py --coco_path /path/to/images --dataset_file taco --num_classes 1 --output_dir taco_1 --resume detr-r50-e632da11.pth```\n",
    "\n",
    "All checkpoints to resume can be downloaded from [official repository](https://github.com/facebookresearch/detr).\n",
    "\n",
    "\n",
    "### 2.1 Train chosen model with parameters:\n",
    "- from sctrach with 1 or 7 classes\n",
    "- fine tuned model detr50 with 1 or 7 classes and with AdamW and LaProp Optimizer: https://github.com/facebookresearch/detr/issues/9 (set ```dataset_file``` as ```taco``` or ```multi```)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Things changed:\n",
    "- the parameter name ```num_classes``` is misleading. It is actually the ID which DETR will reserve for its own no_object class. It should be set to one plus the highest class ID in your dataset. It has to be changed in ```models/detr.py``` in 314 line. We provided argparse argument ```--num_classes```, and put the value ```args.num_classes + 1``` there;\n",
    "- dataset to load: create functions ```build_taco()```, and ```build_multi()``` with parameters in ```datasets/coco.py``` lines 147-192 and modify function build_dataset in ```datasets/__init__.py``` in lines 19-30;\n",
    "- delete head of source model to enable classyfication of proper number of class in ```main.py```: lines 223 - 228;\n",
    "- add new optimizer ```LaProp class``` in util directory - to choose just type ```--optimizer LaProp``` while running a script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Using ```plot_utils.py``` script one can evaluate results - plot loss, mAP ect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training from sctrach\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from util.plot_utils import *\n",
    "from pathlib import Path, PurePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ('loss','class_error','loss_bbox','loss_giou','mAP')  # <-- I put the items of interest here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Training from sctrach on TACO (1.5k images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_logs([Path('/dih4/dih4_2/wimlds/smajchrowska/detr/sctrach_1'), Path('/dih4/dih4_2/wimlds/smajchrowska/detr/sctrach_6')], fields, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fine tuned model on TACO (1.5k images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning first attempt: 1 or 6 classes with ResNet50 and AdamW\n",
    "plot_logs([Path('/dih4/dih4_2/wimlds/smajchrowska/detr/wimlds_1'), Path('/dih4/dih4_2/wimlds/smajchrowska/detr/wimlds_6')], fields, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning second attempt: 1 or 6 classes with ResNet50 and AdamW\n",
    "plot_logs([Path('/dih4/dih4_2/wimlds/smajchrowska/detr/aw_wimlds_1'), Path('/dih4/dih4_2/wimlds/smajchrowska/detr/aw_wimlds_6')], fields, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning third attempt: 1 or 6 classes with ResNet50 and LaProp\n",
    "plot_logs([Path('/dih4/dih4_2/wimlds/smajchrowska/detr/lp_wimlds_1'), Path('/dih4/dih4_2/wimlds/smajchrowska/detr/lp_wimlds_6')], fields, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Fine tuned model on extended TACO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning fourth attempt: 1 or 7 classes with ResNet50\n",
    "plot_logs([Path('/dih4/dih4_2/wimlds/smajchrowska/wimlds_1'), Path('/dih4/dih4_2/wimlds/smajchrowska/wimlds_7')], fields, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Fine tuned model on multi datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning fourth attempt: 1 class with ResNet50 and ResNet101\n",
    "plot_logs([Path('/home/smajchrowska/detect-waste/detr/multi0_1'), Path('/dih4/dih4_2/wimlds/smajchrowska/r101_multi_1')], fields, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Fine tuned model on multi datasets with frozen weights for instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning fourth attempt: 1 class with ResNet50 and ResNet101\n",
    "plot_logs([Path('/dih4/dih4_2/wimlds/smajchrowska/detr_mask')], fields, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand the logs\n",
    "From the log, we can have a basic understanding the training process and know how well the detector is trained.\n",
    "\n",
    "Firstly, the ResNet-50 (or ResNet-101) backbone pre-trained on ImageNet is loaded, this is a common practice since training from scratch is more cost - too long, and not effective enough.\n",
    "\n",
    "Second, since the dataset we are using is small, we loaded a pretrained Detr model and finetune it for detection our classes. The original DETR is trained on COCO dataset which contains 80 classes but in our variation about waste datasets only have 1 class. Therefore, the few last layers (```class_embed.weight```, ```class_embed.bias```, ```query_embed.weight```) of the pre-trained DETR for classification has different weight shape and is not used.\n",
    "\n",
    "Third, after training, the detector is evaluated by the default VOC-style (`mAP@0.5`) evaluation. The results show that the detector achieves ~50.6 mAP on the val dataset for multi bbox one class, not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Check results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo import plot_results, get_transforms, rescale_bboxes, set_model\n",
    "\n",
    "chtype = 'MULTI_BBox'\n",
    "img_name = 'http://media.pixcove.com/V/9/9/Bottle-Flask-Landscapes-Nature-Glass-Bottles-Dispo-8171.jpg'\n",
    "threshold = 0.55\n",
    "\n",
    "if chtype == 'TACO_6':\n",
    "    # TACO2detect_waste classes\n",
    "    CLASSES = [\n",
    "        'Glass', 'Metals and plastics', 'Non recyclable', 'Other', 'Paper', 'Bio'\n",
    "    ]\n",
    "    chpath = '/dih4/dih4_2/wimlds/smajchrowska/detr/aw_wimlds_6/checkpoint.pth'\n",
    "    model_name = 'detr_resnet50'\n",
    "elif chtype == 'TACO_7':\n",
    "    # was trained with annotations begin with id 1\n",
    "    CLASSES = [\n",
    "        'N/A', 'Metals and plastics', 'Other', 'Non recyclable', 'Glass', 'Paper', 'Bio', 'Unknown'\n",
    "    ]\n",
    "    chpath = '/dih4/dih4_2/wimlds/smajchrowska/wimlds_7/checkpoint.pth'\n",
    "    model_name = 'detr_resnet50'\n",
    "elif chtype == 'TACO_1':\n",
    "    # was trained with annotations begin with id 1\n",
    "    CLASSES = [\n",
    "        'N/A', 'Litter'\n",
    "    ]\n",
    "    chpath = '/dih4/dih4_2/wimlds/smajchrowska/wimlds_1/checkpoint.pth'\n",
    "    model_name = 'detr_resnet50'\n",
    "elif chtype == 'MULTI_BBox':\n",
    "    CLASSES = [\n",
    "        'Litter'\n",
    "    ]\n",
    "    chpath = '/home/smajchrowska/detect-waste/detr/multi0_1/checkpoint.pth'\n",
    "    model_name = 'detr_resnet50'\n",
    "elif chtype == 'MULTI_Mask':\n",
    "    CLASSES = [\n",
    "        'Litter'\n",
    "    ]\n",
    "    chpath = f'/dih4/dih4_2/wimlds/smajchrowska/detr_mask/checkpoint.pth'\n",
    "    model_name = 'detr_resnet101_panoptic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "num_classes = len(CLASSES)\n",
    "print(num_classes)\n",
    "model = set_model(model_name, num_classes, chpath, 'cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# get image\n",
    "if img_name.startswith('http'):\n",
    "    im = Image.open(requests.get(img_name, stream=True).raw).convert('RGB')\n",
    "else:\n",
    "    im = Image.open(img_name).convert('RGB')\n",
    "\n",
    "\n",
    "# mean-std normalize the input image (batch-size: 1)\n",
    "img = get_transforms(im)\n",
    "\n",
    "# propagate through the model\n",
    "outputs = model(img)\n",
    "\n",
    "# keep only predictions with 0.x+ confidence\n",
    "probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
    "keep = probas.max(-1).values > threshold\n",
    "\n",
    "# convert boxes from [0; 1] to image scales\n",
    "bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)\n",
    "\n",
    "# plot results\n",
    "plot_results(im, probas[keep], bboxes_scaled, CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "if chtype == 'MULTI_Mask':\n",
    "    # Plot all the remaining masks\n",
    "    ncols = 2\n",
    "    fig, axs = plt.subplots(ncols=ncols, nrows=math.ceil(keep.sum().item() / ncols), figsize=(18, 10))\n",
    "    for i, mask in enumerate(outputs[\"pred_masks\"][0, keep]):\n",
    "        ax = axs[i // ncols, i % ncols]\n",
    "        ax.imshow(mask, cmap=\"cividis\")\n",
    "        ax.axis('off')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detr",
   "language": "python",
   "name": "detr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
