{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: fine-tuning DETR on baloons dataset\n",
    "\n",
    "-   Official DETR repository: https://github.com/facebookresearch/detr\n",
    "-   This notebook base on [the woctezuma fork](https://github.com/woctezuma/detr/tree/finetune)\n",
    "-   Discussion about fine-tuning in [a Github issue](https://github.com/facebookresearch/detr/issues/9).\n",
    "-   A nice blog post about another approach (Mask R-CNN) and the balloon dataset (which we use in this notebook): [here](https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from:\n",
    "-   https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_attention.ipynb\n",
    "-   https://github.com/woctezuma/finetune-detr\n",
    "\n",
    "## Define useful boilerplate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "# standard PyTorch mean-std input image normalization\n",
    "transform = T.Compose([\n",
    "    T.Resize(800),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bboxes_from_outputs(outputs,\n",
    "                               threshold=0.7):\n",
    "  \n",
    "  # keep only predictions with confidence above threshold\n",
    "  probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
    "  keep = probas.max(-1).values > threshold\n",
    "\n",
    "  probas_to_keep = probas[keep]\n",
    "\n",
    "  # convert boxes from [0; 1] to image scales\n",
    "  bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)\n",
    "  \n",
    "  return probas_to_keep, bboxes_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO classes\n",
    "CLASSES = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]\n",
    "\n",
    "# colors for visualization\n",
    "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(pil_img, prob=None, boxes=None):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    if prob is not None and boxes is not None:\n",
    "      for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n",
    "          ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                    fill=False, color=c, linewidth=3))\n",
    "          cl = p.argmax()\n",
    "          text = f'{CLASSES[cl]}: {p[cl]:0.2f}'\n",
    "          ax.text(xmin, ymin, text, fontsize=15,\n",
    "                  bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an image for a demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/train2017/000000310645.jpg'\n",
    "im = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean-std normalize the input image (batch-size: 1)\n",
    "img = transform(im).unsqueeze(0)\n",
    "\n",
    "# propagate through the model\n",
    "outputs = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [0.9, 0.7, 0.0]:\n",
    "  \n",
    "  probas_to_keep, bboxes_scaled = filter_bboxes_from_outputs(outputs,\n",
    "                                                            threshold=threshold)\n",
    "\n",
    "  plot_results(im, probas_to_keep, bboxes_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: if the threshold is equal to zero, then you will see all of the 100 query slots. The zero-threshold is only used for illustration. In usual cases, most query slots have a low confidence score, so that irrelevant query slots would be pruned with a higher threshold, such as 0.7 or 0.9.\n",
    "\n",
    "Reference: https://github.com/facebookresearch/detr/issues/9#issuecomment-635357693\n",
    "\n",
    "NB²: For fine-tuning purposes, we cannot change the number of query slots.\n",
    "\n",
    "> If you're fine-tuning, I don't recommend changing the number of queries on the fly, it is extremely unlikely to work out of the box. In this case you're probably better off retraining from scratch (you can change the --num_queries arg from our training script).\n",
    "\n",
    "Reference: https://github.com/facebookresearch/detr/issues/9#issuecomment-636407752"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained weights\n",
    "\n",
    "Load a check-point (urls can be found [here](https://github.com/facebookresearch/detr#model-zoo)), then remove the classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained weights\n",
    "checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url='https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth',\n",
    "            map_location='cpu',\n",
    "            check_hash=True)\n",
    "\n",
    "# Remove class weights\n",
    "del checkpoint[\"model\"][\"class_embed.weight\"]\n",
    "del checkpoint[\"model\"][\"class_embed.bias\"]\n",
    "\n",
    "# Save\n",
    "torch.save(checkpoint,\n",
    "           'detr-r50_no-class-head.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset for fine-tuning\n",
    "\n",
    "The `balloon` dataset will be used. It is featured here and uses VIA format:\n",
    "-   https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose whether to start indexing categories with 0 or with 1.\n",
    "\n",
    "This is a matter of taste, and it should not impact the performance of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose whether to start indexing categories with 0 or with 1.\n",
    "#\n",
    "# NB: convention in COCO dataset is such that the 1st class (person) has ID n°1.\n",
    "#\n",
    "# NB²: this is why we chose to set to 1 the default value of `first_class_index`\n",
    "# in `via2coco.convert()`.\n",
    "\n",
    "first_class_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code is from https://github.com/woctezuma/VIA2COCO/tree/fixes to convert annotations from VIA format to COCO format.\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import json\n",
    "import math\n",
    "\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "def GetAreaOfPolyGon(points_x, points_y):\n",
    "    points = []\n",
    "    for index in range(len(points_x)):\n",
    "        points.append(Point(points_x[index], points_y[index]))\n",
    "    area = 0\n",
    "    if len(points) < 3:\n",
    "\n",
    "        raise Exception(\"error\")\n",
    "\n",
    "    p1 = points[0]\n",
    "    for i in range(1, len(points) - 1):\n",
    "        p2 = points[1]\n",
    "        p3 = points[2]\n",
    "\n",
    "        vecp1p2 = Point(p2.x - p1.x, p2.y - p1.y)\n",
    "        vecp2p3 = Point(p3.x - p2.x, p3.y - p2.y)\n",
    "\n",
    "        vecMult = vecp1p2.x * vecp2p3.y - vecp1p2.y * vecp2p3.x\n",
    "        sign = 0\n",
    "        if vecMult > 0:\n",
    "            sign = 1\n",
    "        elif vecMult < 0:\n",
    "            sign = -1\n",
    "\n",
    "        triArea = GetAreaOfTriangle(p1, p2, p3) * sign\n",
    "        area += triArea\n",
    "    return abs(area)\n",
    "\n",
    "\n",
    "def GetAreaOfTriangle(p1, p2, p3):\n",
    "\n",
    "    area = 0\n",
    "    p1p2 = GetLineLength(p1, p2)\n",
    "    p2p3 = GetLineLength(p2, p3)\n",
    "    p3p1 = GetLineLength(p3, p1)\n",
    "    s = (p1p2 + p2p3 + p3p1) / 2\n",
    "    area = s * (s - p1p2) * (s - p2p3) * (s - p3p1)\n",
    "    area = math.sqrt(area)\n",
    "    return area\n",
    "\n",
    "\n",
    "def GetLineLength(p1, p2):\n",
    "\n",
    "    length = math.pow((p1.x - p2.x), 2) + math.pow((p1.y - p2.y), 2)\n",
    "    length = math.sqrt(length)\n",
    "    return length\n",
    "\n",
    "\n",
    "\n",
    "def create_image_info(\n",
    "    image_id,\n",
    "    file_name,\n",
    "    image_size,\n",
    "    date_captured=datetime.datetime.utcnow().isoformat(\" \"),\n",
    "    license_id=1,\n",
    "    coco_url=\"\",\n",
    "    flickr_url=\"\",\n",
    "):\n",
    "    image_info = {\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": file_name,\n",
    "        \"width\": image_size[0],\n",
    "        \"height\": image_size[1],\n",
    "        \"date_captured\": date_captured,\n",
    "        \"license\": license_id,\n",
    "        \"coco_url\": coco_url,\n",
    "        \"flickr_url\": flickr_url,\n",
    "    }\n",
    "\n",
    "    return image_info\n",
    "\n",
    "\n",
    "def create_annotation_info(\n",
    "    annotation_id, image_id, category_id, is_crowd, area, bounding_box, segmentation\n",
    "):\n",
    "    annotation_info = {\n",
    "        \"id\": annotation_id,\n",
    "        \"image_id\": image_id,\n",
    "        \"category_id\": category_id,\n",
    "        \"iscrowd\": is_crowd,\n",
    "        \"area\": area,  # float\n",
    "        \"bbox\": bounding_box,  # [x,y,width,height]\n",
    "        \"segmentation\": segmentation,  # [polygon]\n",
    "    }\n",
    "\n",
    "    return annotation_info\n",
    "\n",
    "\n",
    "def get_segmenation(coord_x, coord_y):\n",
    "    seg = []\n",
    "    for x, y in zip(coord_x, coord_y):\n",
    "        seg.append(x)\n",
    "        seg.append(y)\n",
    "    return [seg]\n",
    "\n",
    "\n",
    "def convert(\n",
    "    imgdir,\n",
    "    annpath,\n",
    "    categories=None,\n",
    "    super_categories=None,\n",
    "    output_file_name=None,\n",
    "    first_class_index=1,  # typically, 0 or 1\n",
    "):\n",
    "    \"\"\"\n",
    "    :param imgdir: directory for your images\n",
    "    :param annpath: path for your annotations\n",
    "    :return: coco_output is a dictionary of coco style which you could dump it into a json file\n",
    "    as for keywords 'info','licenses','categories',you should modify them manually\n",
    "    \"\"\"\n",
    "\n",
    "    if categories is None:\n",
    "        categories = [\"rib\", \"clavicle\"]\n",
    "\n",
    "    default_category = categories[0]\n",
    "\n",
    "    category_dict = dict()\n",
    "    for (cat_id, cat_name) in enumerate(categories, start=first_class_index):\n",
    "        category_dict[cat_name] = cat_id\n",
    "\n",
    "    if super_categories is None:\n",
    "        default_super_category = \"bone\"\n",
    "        super_categories = [default_super_category for _ in categories]\n",
    "\n",
    "    coco_output = {}\n",
    "    coco_output[\"info\"] = {\n",
    "        \"description\": \"Example Dataset\",\n",
    "        \"url\": \"https://github.com/waspinator/pycococreator\",\n",
    "        \"version\": \"0.1.0\",\n",
    "        \"year\": 2018,\n",
    "        \"contributor\": \"waspinator\",\n",
    "        \"date_created\": datetime.datetime.utcnow().isoformat(\" \"),\n",
    "    }\n",
    "    coco_output[\"licenses\"] = [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
    "            \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\",\n",
    "        }\n",
    "    ]\n",
    "    coco_output[\"categories\"] = [\n",
    "        {\n",
    "            \"id\": category_dict[cat_name],\n",
    "            \"name\": cat_name,\n",
    "            \"supercategory\": super_cat_name,\n",
    "        }\n",
    "        for (cat_name, super_cat_name) in zip(categories, super_categories)\n",
    "    ]\n",
    "    coco_output[\"images\"] = []\n",
    "    coco_output[\"annotations\"] = []\n",
    "\n",
    "    ann = json.load(open(annpath))\n",
    "    # annotations id start from zero\n",
    "    ann_id = 0\n",
    "    # in VIA annotations, keys are image name\n",
    "    for img_id, key in enumerate(ann.keys()):\n",
    "\n",
    "        filename = ann[key][\"filename\"]\n",
    "        img = Image.open(imgdir + filename)\n",
    "        # make image info and storage it in coco_output['images']\n",
    "        image_info = create_image_info(\n",
    "            img_id, os.path.basename(filename), image_size=img.size\n",
    "        )\n",
    "        # Caveat: image shapes are conventionally (height, width) whereas image sizes are conventionally (width, height)\n",
    "        # References:\n",
    "        # -   https://note.nkmk.me/en/python-opencv-pillow-image-size/\n",
    "        # -   https://github.com/facebookresearch/detectron2/blob/master/detectron2/data/detection_utils.py#L189\n",
    "        coco_output[\"images\"].append(image_info)\n",
    "        regions = ann[key][\"regions\"]\n",
    "        # for one image ,there are many regions,they share the same img id\n",
    "        for region in regions:\n",
    "            region_attributes = regions[region][\"region_attributes\"]\n",
    "            try:\n",
    "                cat_name = region_attributes[\"label\"]\n",
    "            except KeyError:\n",
    "                cat_name = default_category\n",
    "            try:\n",
    "                cat_id = category_dict[cat_name]\n",
    "            except KeyError:\n",
    "                print(\"Skipping unknown category {} in {}\".format(cat_name, filename))\n",
    "                continue\n",
    "            iscrowd = 0\n",
    "            shape_attributes = regions[region][\"shape_attributes\"]\n",
    "            points_x = shape_attributes[\"all_points_x\"]\n",
    "            points_y = shape_attributes[\"all_points_y\"]\n",
    "            area = GetAreaOfPolyGon(points_x, points_y)\n",
    "            min_x = min(points_x)\n",
    "            max_x = max(points_x)\n",
    "            min_y = min(points_y)\n",
    "            max_y = max(points_y)\n",
    "            box = [min_x, min_y, max_x - min_x, max_y - min_y]\n",
    "            segmentation = get_segmenation(points_x, points_y)\n",
    "            # make annotations info and storage it in coco_output['annotations']\n",
    "            ann_info = create_annotation_info(\n",
    "                ann_id, img_id, cat_id, iscrowd, area, box, segmentation\n",
    "            )\n",
    "            coco_output[\"annotations\"].append(ann_info)\n",
    "            ann_id = ann_id + 1\n",
    "\n",
    "    if output_file_name is not None:\n",
    "        print(\"Saving to {}\".format(output_file_name))\n",
    "\n",
    "        with open(output_file_name, \"w\") as f:\n",
    "            json.dump(coco_output, f)\n",
    "\n",
    "    return coco_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the data put it to ```data_path```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/dih4/dih4_2/wimlds/smajchrowska/detr/'\n",
    "\n",
    "for keyword in ['train', 'val']:\n",
    "\n",
    "  input_dir = data_path + 'balloon/' + keyword + '/'\n",
    "  input_json = input_dir + 'via_region_data.json'\n",
    "  categories = ['balloon']\n",
    "  super_categories = ['N/A']\n",
    "  output_json = input_dir + 'custom_' + keyword + '.json'\n",
    "\n",
    "  print('Converting {} from VIA format to COCO format'.format(input_json))\n",
    "\n",
    "  coco_dict = convert(\n",
    "      imgdir=input_dir,\n",
    "      annpath=input_json,\n",
    "      categories=categories,\n",
    "      super_categories=super_categories,\n",
    "      output_file_name=output_json,\n",
    "      first_class_index=first_class_index,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the directory structure to be the following:\n",
    "```\n",
    "path/to/coco/\n",
    "├ annotations/  # JSON annotations\n",
    "│  ├ annotations/custom_train.json\n",
    "│  └ annotations/custom_val.json\n",
    "├ train2017/    # training images\n",
    "└ val2017/      # validation images\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the dataset after it was pre-processed for fine-tuning\n",
    "\n",
    "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
    "-   Demo of COCO API: https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoDemo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pycocotools.coco as coco\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='/dih4/dih4_2/wimlds/smajchrowska/detr/balloon/'\n",
    "dataType='train2017'\n",
    "annFile='{}annotations/instances_{}.json'.format(dataDir, dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize COCO api for instance annotations\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display COCO categories and supercategories\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "\n",
    "nms=[cat['name'] for cat in cats]\n",
    "print('Categories: {}'.format(nms))\n",
    "\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print('Super-categories: {}'.format(nms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display image\n",
    "catIds = coco.getCatIds(catNms=['balloon']);\n",
    "imgIds = coco.getImgIds(catIds=catIds );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = imgIds[np.random.randint(0,len(imgIds))]\n",
    "print('Image n°{}'.format(img_id))\n",
    "\n",
    "img = coco.loadImgs(img_id)[0]\n",
    "\n",
    "img_name = '%s/%s/%s'%(dataDir, dataType, img['file_name'])\n",
    "print('Image name: {}'.format(img_name))\n",
    "\n",
    "I = io.imread(img_name)\n",
    "plt.figure()\n",
    "plt.imshow(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds)\n",
    "anns = coco.loadAnns(annIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display instance annotations\n",
    "plt.imshow(I)\n",
    "coco.showAnns(anns, draw_bbox=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I)\n",
    "coco.showAnns(anns, draw_bbox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning\n",
    "\n",
    "-   Instructions appear in [a Github Gist](https://gist.github.com/woctezuma/e9f8f9fe1737987351582e9441c46b5d).\n",
    "\n",
    "There is a `--frozen_weights` argument. However, it is of no use for box detection. Indeed, \"frozen training is meant for segmentation only\" (as mentioned at this [line](https://github.com/facebookresearch/detr/blob/f4cdc542de34de771da8b9189742e5465f5220cd/main.py#L110) of the source-code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boilerplate variables\n",
    "\n",
    "**Caveat**: the parameter name `num_classes` is misleading. It is actually the ID which DETR will reserve for **its own** `no_object` class. Inside model it should be set to one plus the highest class ID in your dataset.\n",
    "\n",
    "For instance, if you have one class (balloon):\n",
    "- if you used the index n°0 for this class, then `max_id = 0` and `num_classes = max_id+1 = 1`\n",
    "Reference: https://github.com/facebookresearch/detr/issues/108#issuecomment-650269223\n",
    "\n",
    "In our detect-waste project we set ths variable as args.num_classes + 1, so in below cell just leave 1 for one class dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "!python ../main.py \\\n",
    "  --dataset_file \"coco\" \\\n",
    "  --coco_path $dataDir \\\n",
    "  --output_dir \"outputs_ballons\" \\\n",
    "  --resume \"detr-r50_no-class-head.pth\" \\\n",
    "  --epochs 10 \\\n",
    "  --num_classes 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring of training\n",
    "\n",
    "Reference: https://github.com/lessw2020/Thunder-Detr/blob/master/View_your_training_results.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.plot_utils import plot_logs\n",
    "from pathlib import Path\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "finetuned_classes = ['balloon']\n",
    "log_directory = [Path('/dih4/dih4_2/wimlds/smajchrowska/detr/outputs_ballons/')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the code of [`plot_logs`](https://github.com/facebookresearch/detr/blob/5e66b4cd15b2b182da347103dd16578d28b49d69/util/plot_utils.py#L13):\n",
    "-   solid lines are training results,\n",
    "-   dashed lines are validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = (\n",
    "    'loss','class_error','loss_bbox','loss_giou','mAP'\n",
    "    )\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the fine-tuned model\n",
    "\n",
    "- How to replace the classification head: https://github.com/facebookresearch/detr/issues/9#issuecomment-636391562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('facebookresearch/detr',\n",
    "                       'detr_resnet50',\n",
    "                       pretrained=False,\n",
    "                       num_classes=num_classes)\n",
    "\n",
    "checkpoint = torch.load('/dih4/dih4_2/wimlds/smajchrowska/detr/outputs_ballons/checkpoint.pth',\n",
    "                        map_location='cpu')\n",
    "\n",
    "model.load_state_dict(checkpoint['model'],\n",
    "                      strict=False)\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boilerplate functions to display fine-tuned results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_finetuned_results(pil_img, prob=None, boxes=None):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    if prob is not None and boxes is not None:\n",
    "      for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n",
    "          ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                    fill=False, color=c, linewidth=3))\n",
    "          cl = p.argmax()\n",
    "          text = f'{finetuned_classes[cl]}: {p[cl]:0.2f}'\n",
    "          ax.text(xmin, ymin, text, fontsize=15,\n",
    "                  bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_worflow(my_image, my_model):\n",
    "  # mean-std normalize the input image (batch-size: 1)\n",
    "  img = transform(my_image).unsqueeze(0)\n",
    "\n",
    "  # propagate through the model\n",
    "  outputs = my_model(img)\n",
    "\n",
    "  for threshold in [0.9, 0.7]:\n",
    "    \n",
    "    probas_to_keep, bboxes_scaled = filter_bboxes_from_outputs(outputs,\n",
    "                                                               threshold=threshold)\n",
    "\n",
    "    plot_finetuned_results(my_image,\n",
    "                           probas_to_keep, \n",
    "                           bboxes_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With a training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_name = '/dih4/dih4_2/wimlds/smajchrowska/detr/balloon/train2017/145053828_e0e748717c_b.jpg'\n",
    "im = Image.open(img_name)\n",
    "\n",
    "run_worflow(im,\n",
    "            model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With a validation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_name = '/dih4/dih4_2/wimlds/smajchrowska/detr/balloon/val2017/410488422_5f8991f26e_b.jpg'\n",
    "im = Image.open(img_name)\n",
    "\n",
    "run_worflow(im,\n",
    "            model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "finetune_detr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "detr",
   "language": "python",
   "name": "detr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d60e4c5cf8e4e1daa5da44d7d964bef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "14cae8ee590d4ea685a1ccc73e1b9047": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "288d6ddfdd424175adc7b1072d664a2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de487f21df8e48dd90dd8a63b85981d9",
      "max": 166618694,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14cae8ee590d4ea685a1ccc73e1b9047",
      "value": 166618694
     }
    },
    "3699d6ab29104e418041906d64205970": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_288d6ddfdd424175adc7b1072d664a2c",
       "IPY_MODEL_d4e18112413442df98f9d2dc9c0da0d4"
      ],
      "layout": "IPY_MODEL_a32fc523751f4cd0986a53df32e1a2a7"
     }
    },
    "620241f3f8b9448a87ffa56640e71e82": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7980db06ff6e4fc1b075aed6f887dc42",
      "placeholder": "​",
      "style": "IPY_MODEL_88183a6902534682b41bf2e1b67b1adf",
      "value": " 97.8M/97.8M [00:16&lt;00:00, 6.24MB/s]"
     }
    },
    "6b9010a2f7cc46ed916a2235a00964ca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7980db06ff6e4fc1b075aed6f887dc42": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a67b2838f45460d965e84846c9c8c59": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8562dbd6473b4fe0a33200c9131fc37d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3d96afd423c461a99f15026aebc0038",
       "IPY_MODEL_620241f3f8b9448a87ffa56640e71e82"
      ],
      "layout": "IPY_MODEL_98954caf29b541958f396fc3270fbf36"
     }
    },
    "88183a6902534682b41bf2e1b67b1adf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98954caf29b541958f396fc3270fbf36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a32fc523751f4cd0986a53df32e1a2a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3d96afd423c461a99f15026aebc0038": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b9010a2f7cc46ed916a2235a00964ca",
      "max": 102502400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d60e4c5cf8e4e1daa5da44d7d964bef",
      "value": 102502400
     }
    },
    "d4e18112413442df98f9d2dc9c0da0d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a67b2838f45460d965e84846c9c8c59",
      "placeholder": "​",
      "style": "IPY_MODEL_eac2c9fc11c34e5dbb4e1586540c7a19",
      "value": " 159M/159M [00:13&lt;00:00, 11.9MB/s]"
     }
    },
    "de487f21df8e48dd90dd8a63b85981d9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eac2c9fc11c34e5dbb4e1586540c7a19": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
